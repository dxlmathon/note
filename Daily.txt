计划：
1.SSD完全弄懂
2.c++每天做
（不完成1就不干其它的）


1.python写出所有各种损失函数
需要解决的问题
1.什么是人脸识别
1.交叉熵
1、vector与list的区别；线程与进程的区别
1.softmaxlog
2.假如用一张没有训练过的人脸放入你的识别系统，怎么着？
4.adaboost是线性还是非线性的
5.回归于分类的区别
6.几个搜索算法，包括梯度下降，随机搜索等，还有SGD

总结
1.python中的奇异值分解计算出来的v是v.T，其中有个参数是是不是全部分解，要是false的话，出来的u阵不是方阵。
1.np.unique(); np.setdiff1d(); [i for i in range(10) if i > 5]

1.所谓的权重衰减就是给误差函数加称惩罚项的系数，惩罚项一般是权重的二范数，为了防止某一权重过大造成的过拟合。（对某一特征特别敏感）

1.dataAugmentation
 1.翻转 2.旋转一定的角度 3.对比度，饱和度，亮度 4.随机噪声 
 5.放大缩小 6.偏移 7.
1.所谓的逻辑斯蒂回归模型是指：当线性函数的值越接近正无穷，概率值就越接近1；当线性函数的值越接近负无穷，概率值就越接近0。
2.所谓的最大似然估计，就是先假设模型参数，然后计算实验结果的概率是多少，概率越大所对应的参数越接近实际参数。
3.最大熵于原理时概率模型学习的一个准则，最大熵原理认为，学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型时最好的模型。
4.学习的目的时从所有可能的模型中选择最优模型。
1.有时直接导入a然后使用a.b会出现a中没有b这个属性，这时需要直接import a.b
2.使用scipy.io.savemat()可以生成matlab可以读写的mat格式文件
3.winsound.Beep(600, 1000)

1.lambda的用法：匿名函数
ff = lambda x:x**2
print(ff(3))

2.所谓的装饰器，就是调用某函数时先把其放入对应的装饰器中装饰一下。
def f1(func):
    print('fuck')
    return func
@f1
def f2():
    print('you')
f2()

1.python中字符串连接可使用.join
 c = '_'.join(['a', 'b', 'c']), 则c为a_b_c
2.b = a 并不是浅复制，需使用b = a[:]

1.random_state
 为整数时：不随机
 为None时： 随机

1.pr曲线
TP：真正例；FN：假负例
FP：假正例；TN：真负例
precision（查准率）：TP/(TP+FP)
recall(查全率)：TP/(TP+FN)
所谓的F1就是precision和recall的调和平均（越高越好一般）
precision关心预测出的正样本的正确率的问题；查全率关心预测出正样本的保证性。所谓的PR图就是precision vs recall，recall为横轴，precision为纵轴。越饱满性能越好。一般是找个平衡点BEP（precision=recall）。那怎么得出PR曲线呢，是这样子做的：首先将阈值设为1，则recall为0，precision为1；当阈值为0时，全部预测为正样本，则recall为1， precison也为1。

而所谓的ROC曲线则差不多，使用的是：
纵轴：TPR = TP/(TP+FN),即recall
横轴：FPR = FP/(TN+FP)
通过调整阈值得到ROC曲线。首先将阈值设为1，所有都预测为反例，则recall为0，FPR也为0；当阈值设为0，则recall为1， FPR为也为1。

2.偏差和方差
泛化误差可以分解为偏差、方差和噪声之和。
偏差度量了学习算法的期望预测和真是结果的偏离程度。
方差度量了同样大小的训练样本集的变动所导致的学习性能的变化，即数据扰动造成的影响。
噪声可以认为是数据自身的波动性，表达了任何学习算法所能达到泛化误差的下限。
偏差大说明欠拟合，方差大说明过拟合。

1. 一层可以使用多个不同尺寸的卷积核，参考GoogleNet，inception
2. 所谓的bottleNeck就是使用1*1的卷积核将计算次数降低
3. skip connection 解决网络层数加深梯度弥散问题，使得梯度更容易流动到浅层网络中去。参考resnet、densenet
4. 分别对通道和区域进行操作，即所谓的depthWise，先对每个通道进行卷积，使用1*1的卷积对卷积后的通道进行操作。
5.所谓的depthWise就是首先对每个通道进行卷积操作，所有有通道的卷积核参数一致，然后再使用1*1的卷积核将所有通道进行求和，维度为输出维度的大小。传说中的Xception网络就是基于以上设计而来。可大大减少参数量。
6.分组卷积对通道进行随机分组。


Technology
1. 函数内的局部变量名与函数外部局部变量名不冲突
2. 函数会改变输入变量，因此使用深复制较为稳妥
3. 需要函数改变全局变量，可使用global定义函数内变量
5. os.path.exists()
6. fun.__doc__(用"""   """进行说明)

